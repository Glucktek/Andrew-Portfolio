[["Map",1,2,9,10,24,25,62,63,72,73,125,126],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.8.1","content-config-digest","2f8a18c483cefceb","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://voyager.cosmicthemes.com\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":false,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":\"127.0.0.1\",\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{\"/admin\":\"/keystatic\"},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"experimentalDefaultStyles\":true},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"css-variables\",\"themes\":{},\"wrap\":true,\"transformers\":[]},\"remarkPlugins\":[null],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"i18n\":{\"defaultLocale\":\"en\",\"locales\":[\"en\"],\"routing\":{\"prefixDefaultLocale\":false,\"redirectToDefaultLocale\":true,\"fallbackType\":\"redirect\"}},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false},\"legacy\":{\"collections\":false},\"session\":{\"driver\":\"fs-lite\",\"options\":{\"base\":\"/home/agluck/projects/glucktek/Andrew-Portfolio/node_modules/.astro/sessions\"}}}","authors",["Map",11,12],"main-author",{"id":11,"data":13,"filePath":19,"assetImports":20,"digest":22,"deferredRender":23},{"name":14,"avatar":15,"about":16,"email":17,"authorLink":18},"Andrew Gluck","__ASTRO_IMAGE_../main-author/avatar.jpeg","Helping you achieve your goals with the power of technology","andrew.gluck@glucktek.com","https://glucktek.com","src/data/authors/main-author/index.mdx",[21],"../main-author/avatar.jpeg","9e8b5fcda6c2fc89",true,"blog",["Map",26,27,45,46],"en/k3s-raspberry-pi-the-perfect-diy-kubernetes-cluster",{"id":26,"data":28,"body":40,"filePath":41,"assetImports":42,"digest":44,"deferredRender":23},{"title":29,"description":30,"authors":31,"pubDate":33,"heroImage":34,"categories":35,"draft":39},"k3s and Raspberry Pi: The Perfect DIY Kubernetes Cluster","Run k3s Kubernetes on Raspberry Pi! This guide shows you how to build a lightweight cluster for home or homelab. Easy setup & powerful results.",[32],{"id":11,"collection":9},["Date","2025-06-17T00:00:00.000Z"],"__ASTRO_IMAGE_../k3s-raspberry-pi-the-perfect-diy-kubernetes-cluster/heroImage.png",[36,37,38],"Homelab","Kubernetes","DevOps",false,"### Kubernetes, But Make It Snack-Sized&#x20;\n\nI love Kubernetes, and I absolutely love pie. However, let's be real here, if you tried to run Kubernetes on a stack of raspberry pis, they would be more stuffed than me at thanksgiving dinner. Your poor little SBCs start sweating, and no way to loosen the belt.\n\nEnter k3s. The lightweight, certified Kubernetes distribution that’s so slim, it would make a fashion model feel inadequate. Designed by Rancher, k3s is just like Kubernetes: same power, way less bloat.\n\n### Why k3s Rocks My (and Your) Socks off\n\n* Tiny Footprint: k3s is a single binary under 100MB. It’s like Kubernetes, but on a diet.\n* Fast and Furious: Installs in under a minute, even on a Pi. You’ll spend more time making coffee.\n* Low Resource Usage: Perfect for ARM devices and low-power hardware. Your Pis will thank you.\n* Batteries Included: Comes with containerd, Flannel, Traefik, and more, but you can swap them out if you’re picky.\n* Certified K8s: It’s not a toy. k3s passes all CNCF conformance tests. You get the real deal.\n\nWhat Can You Do With a Pi Cluster Running k3s?\n\n* Home automation (Home Assistant, Node-RED, etc.)\n* Self-hosted services (Nextcloud, Gitea, Jellyfin, Immich)\n* Learning and experimentation (CI/CD, GitOps, edge computing)\n* Bragging rights at your next nerd meetup\n\n### How to Use k3s on a Raspberry Pi Cluster\n\nWhat You’ll Need\n\n* 2+ Raspberry Pis (any model works, but 4 or newer is best)\n* SD cards or USB to SSD (Recommended)\n* Network (wired is best, but WiFi works)\n* SSH access to each Pi\n* A little patience and a lot of coffee\n\nStep 1: Prep Your Pis\n\n1. Flash Raspberry Pi OS Lite (or your favorite flavor) onto each SD card.\n2. Enable SSH by dropping an empty file named `ssh` in the `/boot` partition.\n3. Boot up and SSH in to each Pi.\n4. Update everything (because you’re not a monster):\n\n   ```sh\n   sudo apt update && sudo apt upgrade -y\n   ```\n5. Set hostnames so you know who’s who:\n\n   ```sh\n   sudo hostnamectl set-hostname pi-master\n   # or pi-node1, pi-node2, etc.\n   ```\n6. Reboot for good measure.\n\nStep 2: Install k3s on the Master Node\n\nOn your “master” Pi (let’s call it `pi-master`):\n\n```sh\ncurl -sfL https://get.k3s.io | sh -\n```\n\nThis installs k3s and starts the server.\nGrab the node token for your agents:\n\n```sh\nsudo cat /var/lib/rancher/k3s/server/node-token\n```\n\nStep 3: Install k3s on the Worker Nodes\n\nOn each worker Pi:\n\n```sh\ncurl -sfL https://get.k3s.io | K3S_URL=https://\u003CMASTER_IP>:6443 K3S_TOKEN=\u003CNODE_TOKEN> sh -\n```\n\nReplace `\u003CMASTER_IP>` with your master’s IP.\nReplace `\u003CNODE_TOKEN>` with the token you copied.\n\nStep 4: Check Your Cluster\n\nBack on the master:\n\n```sh\nsudo k3s kubectl get nodes\n```\n\nYou should see all your Pis listed as happy, ready nodes. If not, check your network/firewall and make sure the token/IPs are correct.\n\nStep 5: Deploy Something Cool\n\nLet’s deploy a classic Nginx pod:\n\n```sh\nsudo k3s kubectl create deployment nginx --image=nginx\nsudo k3s kubectl expose deployment nginx --port=80 --type=NodePort\n```\n\nFind the NodePort:\n\n```sh\nsudo k3s kubectl get svc\n```\n\nNow hit your Pi’s IP at that port in your browser. Boom! You’re running Kubernetes on a cluster of $35 computers. You absolute legend.\n\n### Final Thoughts\n\nk3s makes Kubernetes accessible, fun, and practical for tinkerers, homelabbers, and edge deployments. Running it on a Raspberry Pi cluster is a fantastic way to learn, experiment, and build cool stuff without breaking the bank or your brain.\n\nSo go forth, cluster up, and may your pods always be healthy and your nodes never taint(ed).","src/data/blog/en/k3s-raspberry-pi-the-perfect-diy-kubernetes-cluster/index.mdx",[43],"../k3s-raspberry-pi-the-perfect-diy-kubernetes-cluster/heroImage.png","9ec4a7a1256cc2e1","en/why-split-dns-is-a-trap-and-you-shouldn-t-fall-for-it",{"id":45,"data":47,"body":57,"filePath":58,"assetImports":59,"digest":61,"deferredRender":23},{"title":48,"description":49,"authors":50,"pubDate":52,"heroImage":53,"categories":54,"draft":39},"Why Split DNS Is a Trap (and You Shouldn’t Fall for It)","A cautionary tale of hair-pulling debug sessions and invisible firewalls",[51],{"id":11,"collection":9},["Date","2025-04-24T00:00:00.000Z"],"__ASTRO_IMAGE_../why-split-dns-is-a-trap-and-you-shouldn-t-fall-for-it/heroImage.jpg",[55,38,36,56],"dns","Networking","I recently had some serious troubles using split DNS in my home network. My prduction workloads are hybrid, some being in the cloud and some in local server rack. I thought I would be clever and implement split dns. Sounds harmless, right? Like maybe you're just *splitting* up the responsibility nicely between your internal and external zones. It even sounds a little... organized?\n\nNah. It's a trap. A shiny, deliciously deceptive trap that seems like a good idea until it makes you question reality, DNS, and your life choices.\n\n---\n\n### What *Is* Split DNS?\n\nSplit DNS is when you configure your internal DNS servers to resolve certain domains (usually internal names or internal versions of public services) differently than the public DNS.\n\nFor example:\n\n* Internal `api.example.com` → 10.10.1.42\n* External `api.example.com` → 203.0.113.42\n\nTo a human? Totally logical. To systems, automation tools, VPNs, and your future self? A recipe for tears.\n\n---\n\n### Why It’s a Bad Idea\n\n#### 1. **Inconsistent State, Inconsistent Bugs**\n\nEverything works fine… until it doesn’t. One laptop on the wrong network path, a recursive DNS server that leaks the wrong answer, or a VPN client that does something \"weird\" — suddenly you're troubleshooting a ghost.\n\n> \"It works for me.\"\\\n> \"Well, it doesn't work on my phone over LTE.\"\\\n> \"What DNS server are you using?\"\\\n> **Cue the spiral.**\n\n---\n\n#### 2. **Breaks Zero Trust and Modern Networking Models**\n\nSplit DNS assumes you *know* who's inside and who's outside. That’s cute. But in 2025, we’ve got hybrid networks, Tailscale, cloud-hosted services, remote employees, and microservices talking across clusters.\n\nSplit DNS doesn’t fit. You want auth-based access, not “can this IP resolve the hostname?”\n\n---\n\n#### 3. **Certificate Misery**\n\nTrying to use Let’s Encrypt or any ACME-based cert issuance when your internal DNS points to an internal IP? Good luck. Your public resolver can’t hit it, and now you're proxying validation requests or running DNS challenges with duct tape.\n\nSSL termination becomes a hellscape of split zones and reverse proxy hacks. Every cert renewal is a ticking time bomb.\n\n---\n\n#### 4. **Caching Nightmares**\n\nThis was the worst nightmare of them all. DNS caching makes split DNS *extra spicy*. Your laptop switches from your office to a café, but it’s still got that internal IP cached. Now your curl command hangs, trying to reach an address that doesn’t exist outside your internal network.\n\nWanna debug that? Hope you love `dig`, `nslookup`, `systemd-resolved`, and crying, lots of crying.\n\n---\n\n### Okay, So What’s the Alternative?\n\n**Use a single, consistent DNS zone** and control access at the **network** or **application** level:\n\n* Use only public DNS entries, even for internal services. (Bad Idea)\n* Hard separations between internal and external services. For internal services internal-only subdomains (`internal.example.com`) instead of dual-purposing a public domain.\n* Embrace Tailscale or VPNs to securely expose internal services without DNS sleight-of-hand.\n\n---\n\n### TL;DR\n\nSplit DNS *seems* like a good idea; until it becomes the source of untraceable bugs, inconsistent behavior, and broken cert automation. Don’t fall into the trap.\n\nIf you need different access levels for different users or locations, solve that with **auth**, not **alternate realities of DNS**.\n\nBecause the moment you’re deep into a split DNS debugging session at 2AM, you’ll understand why this post exists.","src/data/blog/en/why-split-dns-is-a-trap-and-you-shouldn-t-fall-for-it/index.mdx",[60],"../why-split-dns-is-a-trap-and-you-shouldn-t-fall-for-it/heroImage.jpg","8e647b6bb52ce8e7","otherPages",["Map",64,65],"en/privacy-policy",{"id":64,"data":66,"body":69,"filePath":70,"digest":71,"deferredRender":23},{"title":67,"description":68,"draft":39},"Privacy Policy","Example privacy policy for this template","This privacy policy sets out how Example LLC collects, processes, and uses your Personal Information through your use of our Services.\n\n**This is purely for example. Please consult a lawyer for your own privacy policy.**\n\n## Personal Information Collection\n\nWe only collect and use Personal Information to the extent necessary to provide you with the Services. We collect Personal Information for the Website to provide you with a better online experience.\n\n## Personal Information Retention\n\nWe keep Personal Information for the shortest time necessary to provide you with Services and to meet all our legal and compliance obligations. To determine this retention period, we take into account (i) the nature of the Personal Information gathered; and (ii) the nature of our legal and compliance obligations. All Personal Information no longer required by us is destroyed and/or erased.\n\n## Personal Data from Third Parties\n\nWe may, from time to time, obtain Personal Information from third parties to enable us to better tailor our Services to you (Third Party Personal Information). When we obtain Third Party Personal Information, we will notify you within one month. If we use or share Third Party Personal Information, we will notify you immediately.\n\n## Your Rights\n\nWith respect to Personal Information we hold, you have the following rights:\n\n* Access: You may request from us access to your data that we hold on you.\n* Rectification: If the data we hold on you is inaccurate, you may request that we correct it. If the data we hold is incomplete, you may request that we complete it.\n* Erasure: Subject to certain conditions, you may request that we erase all of the data we hold on you.\n* Restrictions: Subject to certain conditions, you may request that we restrict the processing of data we hold on you.\n* Portability: Subject to certain conditions, you may request that we transfer all the data we hold on you to a third party (including yourself).\n* Objection: Subject to certain conditions, you may object to our processing of your data.\n\n## Minors\n\nWe do not knowingly collect information on children under the age of 16 (“Child”). If you become aware that a Child has provided us with Personal Information, please contact us. If we become aware that we have collected Personal Information from a Child without their parent's verifiable authorization to access our Services, we will take steps to remove that information from our servers.\n\n## Third Party Links\n\nOur website contains links to other third-party websites not owned or managed by Example LLC. This privacy policy applies to this website only. If you click a link to a third-party website, the privacy policy of that website will apply. We highly recommend that you read the privacy policies of other websites as they may be different from ours.\n\n## Merger, acquisition, or asset sale\n\nIf Example LLC is involved in a merger, acquisition, or asset sale, your Personal Information may be transferred.\n\n## Contact us\n\nIf you have any questions or suggestions about our privacy policy or want to know more information about Personal Information we hold, please contact us at [support@example.com](mailto:support@example.com).","src/data/otherPages/en/privacy-policy/index.mdx","f82a6d80aa9f2279","projects",["Map",74,75,99,100],"en/mr-builders",{"id":74,"data":76,"body":94,"filePath":95,"assetImports":96,"digest":98,"deferredRender":23},{"title":77,"description":78,"image":79,"technologies":80,"demoUrl":85,"githubUrl":86,"completionDate":87,"keyFeatures":88,"order":93,"draft":39},"MR Builders Website","Static landing page for local construction company.","__ASTRO_IMAGE_../mr-builders/image.png",[81,82,83,84],"Astro","React","TailwindCSS","Docker","https://mr-builders.com","https://github.com/Glucktek/MRBuilders-web",["Date","2025-03-10T00:00:00.000Z"],[89,90,91,92],"SEO optimization suggestions","Content performance analytics","Clean and professional design tailored to the construction industry.","Fully responsive layout for mobile, tablet, and desktop users.",2,"### **Project Overview**\n\nThe MR Builders website is a professional online platform developed for a construction business to showcase their services, portfolio, and contact details. Designed with a user-friendly interface, it aims to enhance customer engagement and provide a seamless browsing experience for potential clients.\n\n### **Technical Implementation**\n\nThe website is built using Astro, ensuring fast and scalable static site generation. JavaScript is utilized for interactive features, while Docker is employed to streamline deployment and containerization for a reliable and efficient development workflow.\\\n\\\n**Role in Project:**\nAs the developer, I managed the end-to-end implementation, from front-end design to deployment, ensuring a seamless and high-performing website.","src/data/projects/en/mr-builders/index.mdx",[97],"../mr-builders/image.png","66e448543fef52ef","en/rke-2-cluster-factory",{"id":99,"data":101,"body":120,"filePath":121,"assetImports":122,"digest":124,"deferredRender":23},{"title":102,"description":103,"image":104,"technologies":105,"completionDate":112,"keyFeatures":113,"order":119,"draft":39},"RKE2 Cluster Factory","Automated Multi-Cluster Kubernetes Platform with Rancher, Ansible, and Terraform","__ASTRO_IMAGE_../rke-2-cluster-factory/image.png",[106,107,108,109,110,111],"Rancher","RKE2","Ansible","OpenTofu","MetalLB","ArgoCD",["Date","2025-05-31T00:00:00.000Z"],[38,114,115,116,117,118],"Infrastructure as Code","Fully Automated Cluster Lifecycle","Dynamic Configuration with Ansible","GitOps-Enabled with ArgoCD","Production-Ready",1,"#### Overview\n\nThis project is a fully automated system for provisioning, managing, and scaling Kubernetes clusters using RKE2, Rancher, Ansible, and Terraform. It’s designed to turn bare metal or virtual machines into a production-ready, GitOps-enabled Kubernetes environment with minimal manual intervention. Primarily focused taking the complexity out of standing up multi cluster Kubernetes environments. I can not attach the actual code here because it is not publicly accessible.&#x20;\n\n---\n\n#### Technical Highlights\n\n* **End-to-End Automation:**\\\n  The entire lifecycle—from initial cluster bootstrap to multi-cluster management and app deployment—is automated. No click-ops, no snowflake clusters.\n* **Ansible-Driven Bootstrap:**\\\n  Ansible playbooks handle the initial provisioning of a parent RKE2 cluster. This includes installing Rancher for cluster management, MetalLB for load balancing, NGINX Ingress for traffic routing, and other supporting tools. The playbooks are modular and idempotent, making them easy to extend or rerun safely.\n* **Terraform + Rancher API:**\\\n  Terraform takes over to interact with Rancher’s API, dynamically creating and registering additional RKE2 clusters as managed resources. This approach allows for infrastructure-as-code management of not just the clusters, but also their Rancher integration.\n* **Dynamic Cluster Configuration:**\\\n  For each new child cluster, Terraform generates Ansible inventories and playbooks on the fly. Ansible then configures each cluster, installing MetalLB, ArgoCD (for GitOps), and any other required tools. This ensures every cluster is consistently configured and production-ready.\n* **GitOps Ready:**\\\n  ArgoCD is deployed automatically to all clusters, enabling continuous delivery and declarative application management from the start.\n* **Scalable and Repeatable:**\\\n  The system is designed to scale horizontally—spin up as many clusters as you need, all managed centrally through Rancher. The automation is fully repeatable, making it easy to rebuild or expand your environment.\n* **Bare Metal Friendly:**\\\n  MetalLB provides load balancing without the need for cloud provider integrations, making this stack ideal for on-premises or hybrid environments.\n\n---\n\n#### Why This Project Stands Out to me\n\n* **Demonstrates advanced automation and orchestration skills across multiple tools and platforms.**\n* **Bridges the gap between infrastructure provisioning and application delivery.**\n* **Showcases expertise in Kubernetes, infrastructure as code, and DevOps best practices.**\n* **Ready for real-world, production-grade use cases—on-prem, cloud, or hybrid.**","src/data/projects/en/rke-2-cluster-factory/index.mdx",[123],"../rke-2-cluster-factory/image.png","f03e3391c0a62f11","resume",["Map",127,128],"en/resume",{"id":127,"data":129,"filePath":429,"assetImports":430,"digest":476},{"diplomas":130,"certifications":135,"experience":147,"hardSkills":211,"softSkills":241,"languages":260,"tools":264},[131],{"title":132,"school":133,"year":134},"Associate of Science - Computer Programming Technologies","Vincennes University",2016,[136,139,142,144],{"title":137,"year":138},"AWS Solutions Architect",2021,{"title":140,"year":141},"MTA: Software Development Fundamentals",2018,{"title":143,"year":141},"MTA: Networking Fundamentals",{"title":145,"year":146},"CompTIA Security+",2017,[148,161,172,184,199],{"title":149,"company":150,"companyImage":151,"dates":152,"location":153,"responsibilities":154},"Sr Software DevOps Engineer","Magnit","__ASTRO_IMAGE_./magnit-logo.png","September 2022 - August 2025","California, United States",[155,156,157,158,159,160],"Orchestrated end-to-end cloud automation for an entire department using Pulumi (TypeScript), delivering fully reproducible, policy-compliant infrastructure with zero-touch environments.","Engineered robust CI/CD pipelines for a microservices ecosystem, standardizing builds, testing, security scanning, and deployments to dramatically increase release reliability and speed.","Stood up a Rancher-managed Kubernetes platform (RKE2/k3s), automating management-cluster bootstrap and downstream cluster provisioning with Ansible and Terraform for repeatable, auditable cluster lifecycle management.","Implemented a production-grade GitOps operating model with ArgoCD, enforcing declarative deployments, drift detection, and automated rollbacks across environments.","Automated 30% of developer workflows, eliminating manual toil, accelerating feedback loops, and enabling self-service delivery for product teams.","Established guardrails and golden paths (templates, pipelines, policies) that scaled across teams, improving security posture and consistency without slowing delivery.",{"title":162,"company":163,"companyImage":164,"dates":165,"location":166,"responsibilities":167},"Senior DevOps Engineer","Voxr AI Corp","__ASTRO_IMAGE_./voxr-logo.png","February 2024 - June 2025","Louisville Metropolitan Area",[168,169,170,171],"Weekend and evening contract work","Built out entire CI/CD process","Designed scalable robust cloud platform to allow for cost effectiveness in early stages of application development","Consulted on DevOps best practices",{"title":173,"company":174,"companyImage":175,"dates":176,"location":177,"responsibilities":178},"Principal DevOps Engineer","Quanterix","__ASTRO_IMAGE_./quanterix-logo.png","September 2021 - August 2022","Boston, Massachusetts, United States",[179,180,181,182,183],"Pioneered DevOps across the organization—established the philosophy, operating model, and end-to-end pipelines; evangelized best practices to leadership and engineering to drive company-wide adoption.","Converted manual, days-long release processes into fully automated pipelines, shrinking deployments and validations to minutes while increasing reliability and repeatability.","Designed developer-centric workflows (branching, reviews, environments, artifact/version strategy) that streamlined delivery, improved feedback loops, and unlocked self-service.","Implemented Infrastructure as Code with Pulumi, enabling consistent, policy-compliant provisioning and rapid environment spin-up across teams.","Built and evolved hybrid cloud foundations in AWS and Azure, including networking, identity, security guardrails, and platform services to support product growth.",{"title":185,"company":186,"companyImage":187,"dates":188,"location":189,"responsibilities":190},"Lead DevOps Engineer","EAGLE6","__ASTRO_IMAGE_./rocket-icon.png","March 2018 - September 2021","Louisville, Kentucky Area",[191,192,193,194,195,196,197,198],"Developed custom tools to meet organizational needs in Golang and Python","Developed build scripts to allow developers to build the product locally using Ansible","Developed automated configuration of entire AWS infrastructure using AWX, RedHat's open-source variant of Ansible tower","Converted the provisioning of all legacy infrastructure to Terraform and AWX","Continued development of CI/CD pipeline with Jenkins to ensure security and quality are maintained with all software releases","Managed Octopus Server to orchestrate releases to all environments from development to Demo servers","Managed a fleet of over 200 Linux servers","Performed monthly red team security attacks against products to ensure no externally facing vulnerabilities",{"title":200,"company":201,"companyImage":187,"dates":202,"location":189,"responsibilities":203},"Full-stack Developer","ALTOUR","September 2017 - January 2018",[204,205,206,207,208,209,210],"Acted as DevOps engineer for the team","Managed on-premises Linux environments from development to production","Automated deployments to production systems","Internal corporate development","HTML5/JavaScript Front End Design","Built MVC web applications on the CodeIgniter framework","Linux system administration (CentOS, RedHat enterprise derivative)",[212,215,217,219,221,224,226,229,231,233,236,238],{"skill":213,"percentage":214},"AWS/Cloud Platforms",96,{"skill":37,"percentage":216},95,{"skill":218,"percentage":216},"CI/CD Pipelines",{"skill":220,"percentage":216},"Linux Administration",{"skill":222,"percentage":223},"Pulumi/Terraform",90,{"skill":225,"percentage":223},"Docker/Containers",{"skill":227,"percentage":228},"Python",85,{"skill":230,"percentage":228},"Golang",{"skill":232,"percentage":228},"GitOps/ArgoCD",{"skill":234,"percentage":235},"TypeScript/JavaScript",75,{"skill":81,"percentage":237},65,{"skill":239,"percentage":240},"React/React Native",50,[242,245,248,251,254,257],{"skill":243,"icon":244},"Leadership","tabler:user-star",{"skill":246,"icon":247},"Team Collaboration","tabler:users",{"skill":249,"icon":250},"Mentoring","tabler:school",{"skill":252,"icon":253},"Problem Solving","tabler:bulb",{"skill":255,"icon":256},"Process Improvement","tabler:trending-up",{"skill":258,"icon":259},"Strategic Planning","tabler:target",[261],{"language":262,"level":263},"English",10,[265,270,274,277,281,285,289,292,296,299,302,305,309,313,317,321,324,327,330,334,338,342,346,349,353,357,361,365,368,372,376,380,384,388,392,395,399,403,407,411,415,419,422,425],{"name":266,"category":267,"image":268,"link":269},"AWS","Cloud","__ASTRO_IMAGE_./aws-logo.png","https://aws.amazon.com",{"name":227,"category":271,"image":272,"link":273},"Programming","__ASTRO_IMAGE_./python-logo.png","https://python.org",{"name":230,"category":271,"image":275,"link":276},"__ASTRO_IMAGE_./golang-logo.png","https://golang.org",{"name":278,"category":271,"image":279,"link":280},"TypeScript","__ASTRO_IMAGE_./typescript-logo.png","https://typescriptlang.org",{"name":282,"category":271,"image":283,"link":284},"JavaScript","__ASTRO_IMAGE_./javascript-logo.png","https://developer.mozilla.org/en-US/docs/Web/JavaScript",{"name":286,"category":271,"image":287,"link":288},"Bash","__ASTRO_IMAGE_./bash-logo.png","https://www.gnu.org/software/bash/",{"name":81,"category":271,"image":290,"link":291},"__ASTRO_IMAGE_./astro-logo.svg","https://astro.build",{"name":293,"category":271,"image":294,"link":295},"Bun","__ASTRO_IMAGE_./bun-logo.svg","https://bun.sh",{"name":82,"category":271,"image":297,"link":298},"__ASTRO_IMAGE_./react-logo.png","https://react.dev",{"name":300,"category":271,"image":297,"link":301},"React Native","https://reactnative.dev",{"name":83,"category":271,"image":303,"link":304},"__ASTRO_IMAGE_./tailwind-logo.png","https://tailwindcss.com",{"name":306,"category":271,"image":307,"link":308},"HTML5","__ASTRO_IMAGE_./html5-logo.png","https://developer.mozilla.org/en-US/docs/Web/HTML",{"name":310,"category":271,"image":311,"link":312},"CSS3","__ASTRO_IMAGE_./css3-logo.png","https://developer.mozilla.org/en-US/docs/Web/CSS",{"name":314,"category":267,"image":315,"link":316},"ECS","__ASTRO_IMAGE_./ecs-logo.png","https://aws.amazon.com/ecs/",{"name":318,"category":267,"image":319,"link":320},"EKS","__ASTRO_IMAGE_./eks-logo.png","https://aws.amazon.com/eks/",{"name":322,"category":267,"image":268,"link":323},"CloudFormation","https://aws.amazon.com/cloudformation/",{"name":84,"category":38,"image":325,"link":326},"__ASTRO_IMAGE_./docker-logo.png","https://docker.com",{"name":37,"category":38,"image":328,"link":329},"__ASTRO_IMAGE_./kubernetes-logo.png","https://kubernetes.io",{"name":331,"category":38,"image":332,"link":333},"Helm","__ASTRO_IMAGE_./helm-logo.png","https://helm.sh",{"name":335,"category":38,"image":336,"link":337},"Jenkins","__ASTRO_IMAGE_./jenkins-logo.png","https://jenkins.io",{"name":339,"category":38,"image":340,"link":341},"GitHub Actions","__ASTRO_IMAGE_./github-logo.png","https://github.com/features/actions",{"name":343,"category":38,"image":344,"link":345},"GitLab CI","__ASTRO_IMAGE_./gitlab-logo.png","https://docs.gitlab.com/ee/ci/",{"name":111,"category":38,"image":347,"link":348},"__ASTRO_IMAGE_./argocd-logo.png","https://argoproj.github.io/cd",{"name":350,"category":38,"image":351,"link":352},"FluxCD","__ASTRO_IMAGE_./fluxcd-logo.png","https://fluxcd.io",{"name":354,"category":38,"image":355,"link":356},"Linux","__ASTRO_IMAGE_./linux-logo.png","https://kernel.org",{"name":358,"category":38,"image":359,"link":360},"Terraform","__ASTRO_IMAGE_./terraform-logo.png","https://terraform.io",{"name":362,"category":38,"image":363,"link":364},"Pulumi","__ASTRO_IMAGE_./pulumi-logo.svg","https://pulumi.com",{"name":108,"category":38,"image":366,"link":367},"__ASTRO_IMAGE_./ansible-logo.png","https://ansible.com",{"name":369,"category":38,"image":370,"link":371},"Grafana","__ASTRO_IMAGE_./grafana-logo.png","https://grafana.com",{"name":373,"category":38,"image":374,"link":375},"Prometheus","__ASTRO_IMAGE_./prometheus-logo.png","https://prometheus.io",{"name":377,"category":38,"image":378,"link":379},"Vault","__ASTRO_IMAGE_./vault-logo.svg","https://vaultproject.io",{"name":381,"category":38,"image":382,"link":383},"Packer","__ASTRO_IMAGE_./packer-logo.svg","https://packer.io",{"name":385,"category":38,"image":386,"link":387},"Loki","__ASTRO_IMAGE_./logo-loki.svg","https://grafana.com/oss/loki",{"name":389,"category":38,"image":390,"link":391},"Redis","__ASTRO_IMAGE_./redis-logo.png","https://redis.io",{"name":106,"category":38,"image":393,"link":394},"__ASTRO_IMAGE_./rancher-logo.svg","https://rancher.com",{"name":396,"category":38,"image":397,"link":398},"Podman","__ASTRO_IMAGE_./podman-logo.svg","https://podman.io",{"name":400,"category":38,"image":401,"link":402},"New Relic","__ASTRO_IMAGE_./newrelic-logo.svg","https://newrelic.com",{"name":404,"category":38,"image":405,"link":406},"PostgreSQL","__ASTRO_IMAGE_./postgresql-logo.png","https://postgresql.org",{"name":408,"category":38,"image":409,"link":410},"MySQL","__ASTRO_IMAGE_./mysql-logo.png","https://mysql.com",{"name":412,"category":38,"image":413,"link":414},"SQLite","__ASTRO_IMAGE_./sqlite-logo.png","https://sqlite.org",{"name":416,"category":38,"image":417,"link":418},"K3s","__ASTRO_IMAGE_./k3s-logo.svg","https://k3s.io",{"name":107,"category":38,"image":420,"link":421},"__ASTRO_IMAGE_./rke2-logo.svg","https://docs.rke2.io",{"name":423,"category":38,"image":374,"link":424},"MinIO","https://min.io",{"name":426,"category":38,"image":427,"link":428},"Traefik","__ASTRO_IMAGE_./traefik-logo.png","https://traefik.io","src/data/resume/en/resume/index.json",[431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475],"./magnit-logo.png","./voxr-logo.png","./quanterix-logo.png","./rocket-icon.png","./aws-logo.png","./python-logo.png","./golang-logo.png","./typescript-logo.png","./javascript-logo.png","./bash-logo.png","./astro-logo.svg","./bun-logo.svg","./react-logo.png","./tailwind-logo.png","./html5-logo.png","./css3-logo.png","./ecs-logo.png","./eks-logo.png","./docker-logo.png","./kubernetes-logo.png","./helm-logo.png","./jenkins-logo.png","./github-logo.png","./gitlab-logo.png","./argocd-logo.png","./fluxcd-logo.png","./linux-logo.png","./terraform-logo.png","./pulumi-logo.svg","./ansible-logo.png","./grafana-logo.png","./prometheus-logo.png","./vault-logo.svg","./packer-logo.svg","./logo-loki.svg","./redis-logo.png","./rancher-logo.svg","./podman-logo.svg","./newrelic-logo.svg","./postgresql-logo.png","./mysql-logo.png","./sqlite-logo.png","./k3s-logo.svg","./rke2-logo.svg","./traefik-logo.png","da3f40656f3aa0bc"]